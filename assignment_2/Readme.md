# Session 2 Assignment

## Overall Network Training in Excel
![Alt text](backprop_excel.png?raw=true "Backpropagation in Excels")


## Major Steps
* Forward pass - Based on randomally intialized weight w1..w8 calculate vallue for each neurons.
```
    h1 = w1*i1+w2*i2; h2 = w3*i1+w4*i2
    a_h1 = œÉ(h1); a_h2 = œÉ(h2)
    o1 = w5*a_h1+w6*a_h2; o2 = w7*a_h1+w8*a_h2
    a_o1 = œÉ(o1); a_o2 = œÉ(o2)
```

* Calculate the L2 error
```
    E1 = 1/2(t1-a_o1)^2
    E2 = 1/2(t2-a_o2)^2
```	

* Backpropagate Error to update weights w1..w8 using ```w(i+1) = w(i) - lr*Œ¥(Error)/Œ¥w(i)```
** Gradient calculation-
    ```
    Œ¥(E)/Œ¥(w1) = Œ¥(E1)/Œ¥(w1) + Œ¥(E2)/Œ¥(w1) where;
    Œ¥(E1)/Œ¥(w1) = (a_o1-t1)*a_o1*(1-a_o1)*w5*a_h1*(1-a_h1)*i1					
    Œ¥(E2)/Œ¥(w1) = (a_o2-t2)*a_o2*(1-a_o2)*w7*a_h1*(1-a_h1)*i1

    Œ¥(E)/Œ¥(w2) = Œ¥(E1)/Œ¥(w2) + Œ¥(E2)/Œ¥(w2) where;
    Œ¥(E1)/Œ¥(w2) =  (a_o1-t1)*a_o1*(1-a_o1)*w5*a_h1*(1-a_h1)*i2					
    Œ¥(E2)/Œ¥(w2) = (a_o2-t2)*a_o2*(1-a_o2)*w7*a_h1*(1-a_h1)*i2

    Œ¥(E)/Œ¥(w2) = Œ¥(E1)/Œ¥(w3) + Œ¥(E2)/Œ¥(w3) where;
    Œ¥(E1)/Œ¥(w3) =  (a_o1-t1)*a_o1*(1-a_o1)*w6*a_h2*(1-a_h2)*i1					
    Œ¥(E2)/Œ¥(w3) =  (a_o2-t2)*a_o2*(1-a_o2)*w8*a_h2*(1-a_h2)*i1	

    Œ¥(E)/Œ¥(w2) = Œ¥(E1)/Œ¥(w4) + Œ¥(E2)/Œ¥(w4) where;
    Œ¥(E1)/Œ¥(w4) =  (a_o1-t1)*a_o1*(1-a_o1)*w6*a_h2*(1-a_h2)*i2					
    Œ¥(E2)/Œ¥(w4) =  (a_o2-t2)*a_o2*(1-a_o2)*w8*a_h2*(1-a_h2)*i2	

    ùúπ(Error)/Œ¥w5  = (a_o1-t1)*a_o1*(1-a_o1)*a_h1

    ùúπ(Error)/Œ¥w6  = (a_o1-t1)*a_o1*(1-a_o1)*a_h2	

    ùúπ(Error)/Œ¥w7  = (a_o2-t2)*a_o2*(1-a_o2)*a_h1	

    ùúπ(Error)/Œ¥w8  = (a_o2-t2)*a_o2*(1-a_o2)*a_h2								
    ```

* Training Error with different Learning Rates
![Alt text](error_with_varraying_learning_rate.png?raw=true "Error with diff Learning Rates")
